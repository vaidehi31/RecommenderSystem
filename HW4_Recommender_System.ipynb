{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4- Recommender System.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaidehi31/RecommenderSystem/blob/main/HW4_Recommender_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Qe3-_YTPLaO"
      },
      "source": [
        "# Spark Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCDm5v1oPPYz"
      },
      "source": [
        "# installation \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://apache.mirrors.hoobly.com/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!tar -xvf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPATUo6VRCNu"
      },
      "source": [
        "# Recommeder System for MovieLens dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDYCkD1tRHnb"
      },
      "source": [
        "#Import libraries\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
        "\n",
        "from pyspark.sql import Row"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIJOJHXoRct8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9cfa8234-eb8f-4a72-a795-309ccf858725"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data  spark-2.4.5-bin-hadoop2.7  spark-2.4.5-bin-hadoop2.7.tgz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcmTvz--oRld"
      },
      "source": [
        "# Step 1. Read data - Import the MovieLens Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azPNyf3_kYmv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "217b444b-ddb7-4301-8806-b7466c87d7ef"
      },
      "source": [
        "#load ratings data from the MovieLens dataset, each row consisting of a user, a movie, a rating and a timestamp\n",
        "lines = spark.read.text(\"/content/drive/Shared drives/Analytics for Big Data/HW4/ml-100k/u.data\").rdd  \n",
        "parts = lines.map(lambda row: row.value.split(\"\\t\"))\n",
        "ratingsRDD = parts.map(lambda p: Row(userId=int(p[0]), movieId=int(p[1]),\n",
        "                                     rating=float(p[2]), timestamp=float(p[3])))\n",
        "ratings = spark.createDataFrame(ratingsRDD)\n",
        "ratings.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------+------------+------+\n",
            "|movieId|rating|   timestamp|userId|\n",
            "+-------+------+------------+------+\n",
            "|    242|   3.0|8.81250949E8|   196|\n",
            "|    302|   3.0|8.91717742E8|   186|\n",
            "|    377|   1.0|8.78887116E8|    22|\n",
            "|     51|   2.0|8.80606923E8|   244|\n",
            "|    346|   1.0|8.86397596E8|   166|\n",
            "|    474|   4.0|8.84182806E8|   298|\n",
            "|    265|   2.0|8.81171488E8|   115|\n",
            "|    465|   5.0|8.91628467E8|   253|\n",
            "|    451|   3.0|8.86324817E8|   305|\n",
            "|     86|   3.0|8.83603013E8|     6|\n",
            "|    257|   2.0|8.79372434E8|    62|\n",
            "|   1014|   5.0|8.79781125E8|   286|\n",
            "|    222|   5.0| 8.7604234E8|   200|\n",
            "|     40|   3.0|8.91035994E8|   210|\n",
            "|     29|   3.0|8.88104457E8|   224|\n",
            "|    785|   3.0|8.79485318E8|   303|\n",
            "|    387|   5.0|8.79270459E8|   122|\n",
            "|    274|   2.0|8.79539794E8|   194|\n",
            "|   1042|   4.0|8.74834944E8|   291|\n",
            "|   1184|   2.0|8.92079237E8|   234|\n",
            "+-------+------+------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWR2U97jKOmC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "71e49221-71fe-434b-9039-55f848f6ce2c"
      },
      "source": [
        "#Dropping Timestamp column\n",
        "ratings = ratings.drop(\"timestamp\")\n",
        "ratings.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------+------+\n",
            "|movieId|rating|userId|\n",
            "+-------+------+------+\n",
            "|    242|   3.0|   196|\n",
            "|    302|   3.0|   186|\n",
            "|    377|   1.0|    22|\n",
            "|     51|   2.0|   244|\n",
            "|    346|   1.0|   166|\n",
            "|    474|   4.0|   298|\n",
            "|    265|   2.0|   115|\n",
            "|    465|   5.0|   253|\n",
            "|    451|   3.0|   305|\n",
            "|     86|   3.0|     6|\n",
            "|    257|   2.0|    62|\n",
            "|   1014|   5.0|   286|\n",
            "|    222|   5.0|   200|\n",
            "|     40|   3.0|   210|\n",
            "|     29|   3.0|   224|\n",
            "|    785|   3.0|   303|\n",
            "|    387|   5.0|   122|\n",
            "|    274|   2.0|   194|\n",
            "|   1042|   4.0|   291|\n",
            "|   1184|   2.0|   234|\n",
            "+-------+------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXc4Gto_obeo"
      },
      "source": [
        "# Split training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe-XaxFmoiT4"
      },
      "source": [
        "(training, test) = ratings.randomSplit([0.8, 0.2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t-OGfqDoH6-"
      },
      "source": [
        "# Step 2. Build the recommendation model using ALS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP5-_OUjKO3-"
      },
      "source": [
        "als_original = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", nonnegative=True)\n",
        "model = als_original.fit(training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86f1DjJRLKPn"
      },
      "source": [
        "# Step 3. Reporting the Original Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hkde0BcqLMUD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dcc272b8-47eb-4109-c7b8-680d565de2c3"
      },
      "source": [
        "# Evaluate the model by computing the RMSE on the test data\n",
        "predictions = model.transform(test)\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(\"Original Root-mean-square error = \" + str(rmse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Root-mean-square error = nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyUZlrpwf_lf"
      },
      "source": [
        "As we can see rmse is coming out to be nan. This is the cold start problem.\n",
        "\n",
        "In this, Spark assigns NaN predictions during ALSModel. To solve this problem, spark allows dropping rows in the DataFrame of predictions that contain NaN values. It is done by setting coldStartStrategy parameter to \"drop\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kQtwp2gMnlD"
      },
      "source": [
        "# Step 4a. Solving the cold start problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4O7rSdyMqu3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f3444166-3047-4ae7-c02e-983f9753b71b"
      },
      "source": [
        "als_new = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", nonnegative=True, coldStartStrategy= \"drop\")\n",
        "model = als_new.fit(training)\n",
        "\n",
        "# Evaluate the model by computing the RMSE on the test data\n",
        "predictions = model.transform(test)\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(\"Root-mean-square error = \" + str(rmse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Root-mean-square error = 0.9165699485658979\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5ijB8Z0NAYz"
      },
      "source": [
        "The RMSE is coming out to be 0.916, now trying to imrpove the performance using Cross Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i_9tmXyfzEJ"
      },
      "source": [
        "# Step 4b. Performance improvement using Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neV-GJx5NqV-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf3f501c-b917-48da-e319-79b91d7716a6"
      },
      "source": [
        "from pyspark.ml.tuning import CrossValidator\n",
        "from pyspark.ml.tuning import ParamGridBuilder\n",
        "\n",
        "model_new = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", nonnegative = True, coldStartStrategy=\"drop\")\n",
        "\n",
        "# Parameters for tuning\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(model_new.regParam, [0.1, 0.01, 0.001]) \\\n",
        "    .addGrid(model_new.rank, [5, 10, 15]) \\\n",
        "    .build()\n",
        "\n",
        "crossvalidation = CrossValidator(estimator = model_new,\n",
        "                     estimatorParamMaps = paramGrid,\n",
        "                     evaluator = evaluator,\n",
        "                     numFolds=10)\n",
        "\n",
        "#Using the Best Model\n",
        "model_cv = crossvalidation.fit(training).bestModel\n",
        "\n",
        "#Evaluate and print the predictions\n",
        "print(\"RMSE value after solving cold start problem is: \", evaluator.evaluate(model_cv.transform(test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE value after solving cold start problem is:  0.9178132964212179\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueR42feKRRaT"
      },
      "source": [
        "As we can see, even after CV there isn't much improvement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6Rs5xEQhmjW"
      },
      "source": [
        "# Step 5. Top 10 movies for all the users "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN1vLtJ3htE1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "51cb3555-e0de-4ca4-949a-50d383ee64b9"
      },
      "source": [
        "recommendations = model_cv.recommendForAllUsers(10)\n",
        "recommendations.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+--------------------+\n",
            "|userId|     recommendations|\n",
            "+------+--------------------+\n",
            "|   471|[[867, 4.883415],...|\n",
            "|   463|[[19, 4.4390416],...|\n",
            "|   833|[[1368, 5.366121]...|\n",
            "|   496|[[320, 4.9004207]...|\n",
            "|   148|[[1104, 5.207343]...|\n",
            "|   540|[[1449, 4.8793826...|\n",
            "|   392|[[1449, 5.308921]...|\n",
            "|   243|[[1512, 4.404202]...|\n",
            "|   623|[[1450, 4.577325]...|\n",
            "|   737|[[1449, 4.739571]...|\n",
            "|   897|[[1368, 5.0980883...|\n",
            "|   858|[[1512, 4.4579964...|\n",
            "|    31|[[1463, 5.4224477...|\n",
            "|   516|[[1449, 4.6970286...|\n",
            "|   580|[[793, 5.293725],...|\n",
            "|   251|[[1643, 4.909021]...|\n",
            "|   451|[[1269, 4.6691117...|\n",
            "|    85|[[1643, 4.5083456...|\n",
            "|   137|[[1500, 5.837367]...|\n",
            "|   808|[[1449, 5.558436]...|\n",
            "+------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbNCvrmzP32A"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "recommendations = recommendations.toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy5h4vCBRisL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e166fe35-501b-4227-e674-c9d7bf2ceeb1"
      },
      "source": [
        "#Initialize lists that will be used for converting to dataframe\n",
        "list_users = []\n",
        "list_recs = []\n",
        "\n",
        "#Iterate over the whole data set\n",
        "for i in range(len(recommendations)):\n",
        "  #Add userId to user list\n",
        "  list_users.append(recommendations.iloc[i,0])\n",
        "  \n",
        "  #Initialize a string for storing a given user's recommendations\n",
        "  user_recs = \"\" \n",
        "\n",
        "  #Iterate over all recommendations and pick the movieIds\n",
        "  for item in recommendations.iloc[i,1]:\n",
        "    user_recs = user_recs + \", \" + str(item.asDict()[\"movieId\"])\n",
        "\n",
        "  list_recs.append(user_recs[2:])\n",
        "\n",
        "recommendations_df = pd.DataFrame(data = zip(list_users, list_recs), columns=[\"user\", \"recommendations\"])\n",
        "recommendations_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>recommendations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>471</td>\n",
              "      <td>867, 1598, 1468, 102, 189, 263, 1154, 916, 477...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>463</td>\n",
              "      <td>19, 947, 958, 1449, 963, 835, 318, 1642, 740, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>833</td>\n",
              "      <td>1368, 1463, 320, 1104, 1643, 838, 922, 1597, 8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>496</td>\n",
              "      <td>320, 1664, 1449, 793, 475, 75, 1467, 1114, 613...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>148</td>\n",
              "      <td>1104, 1449, 1643, 512, 344, 168, 408, 1607, 43...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user                                    recommendations\n",
              "0   471  867, 1598, 1468, 102, 189, 263, 1154, 916, 477...\n",
              "1   463  19, 947, 958, 1449, 963, 835, 318, 1642, 740, ...\n",
              "2   833  1368, 1463, 320, 1104, 1643, 838, 922, 1597, 8...\n",
              "3   496  320, 1664, 1449, 793, 475, 75, 1467, 1114, 613...\n",
              "4   148  1104, 1449, 1643, 512, 344, 168, 408, 1607, 43..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUhmoHoYR7r3"
      },
      "source": [
        "#Write to a text file\n",
        "with open(\"recommendations.txt\", \"w\") as f:\n",
        "  f.write(\"userId\\trecommendations\\n\")\n",
        "  for i in range(len(recommendations_df)):\n",
        "    f.write(str(recommendations_df.iloc[i,0]) + \"\\t\" + recommendations_df.iloc[i,1] + \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}